{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Playing with texture coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import anny\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "from anny.paths import ANNY_ROOT_DIR\n",
    "import trimesh\n",
    "import yaml\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Instanciate the body model.\n",
    "\n",
    "By default Anny uses quad faces, but here we are going to use triangulate the mesh in order to be able to use the trimesh library for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "anny_model = anny.create_fullbody_model(eyes=True, tongue=True, triangulate_faces=True)\n",
    "trimesh.Trimesh(anny_model.template_vertices.cpu().numpy(),\n",
    "                faces=anny_model.faces.cpu().numpy()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Each vertex of each face of the model is associated with some 2D ST texture coordinates.\n",
    "It enables to unwrap the mesh onto a 2D image, as illustrated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty image with white background\n",
    "width, height = 1024, 1024\n",
    "uv_unwrap_image = PIL.Image.new(\"RGB\", (width, height), (0,0,0))\n",
    "\n",
    "# Draw face contours on the texture image\n",
    "faces = anny_model.faces.cpu().numpy()\n",
    "face_texture_coordinates_indices = anny_model.face_texture_coordinate_indices.numpy()\n",
    "st = anny_model.texture_coordinates.numpy()\n",
    "vertex_absolute_texture_coordinates = np.array([0, height])[None] + st * np.array([width, -height])[None] \n",
    "draw = PIL.ImageDraw.Draw(uv_unwrap_image)\n",
    "for face_texture_ids in face_texture_coordinates_indices:\n",
    "    u0, v0 = vertex_absolute_texture_coordinates[face_texture_ids[-1]]\n",
    "    for i in face_texture_ids:\n",
    "        u,v = vertex_absolute_texture_coordinates[i]\n",
    "        draw.line(((u0, v0), (u, v)), fill=(128,128,128), width=1)\n",
    "        u0, v0 = u, v  # Update the starting point for the next line\n",
    "display(uv_unwrap_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Body part segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "We provide a basic segmentation of the mesh of Anny into different semantic body parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ANNY_ROOT_DIR / \"data/segmentation/body_parts_segmentation.png\"\n",
    "body_parts_segmentation_image = PIL.Image.open(path).convert(\"RGB\")\n",
    "\n",
    "overlay_image = body_parts_segmentation_image.copy()\n",
    "mask = PIL.Image.fromarray(np.all(np.asarray(uv_unwrap_image) != 0, axis=-1))\n",
    "overlay_image.paste(uv_unwrap_image, mask=mask)\n",
    "display(overlay_image)\n",
    "\n",
    "with open(ANNY_ROOT_DIR / \"data/segmentation/body_parts_segmentation.yaml\", \"r\") as f:\n",
    "    body_parts_segmentation = yaml.safe_load(f)\n",
    "display(f\"Body parts: {list(body_parts_segmentation['colors'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 3D visualization\n",
    "**Note:** we need to duplicate vertices as trimesh expects one texture coordinate per vertex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = anny_model.template_vertices.detach().cpu().numpy()\n",
    "faces = faces\n",
    "uv = anny_model.texture_coordinates.cpu().numpy()\n",
    "duplicated_vertices = vertices[faces.flatten()]\n",
    "duplicated_faces = np.arange(3 * len(faces)).reshape(-1, 3)\n",
    "duplicated_uvs = uv[anny_model.face_texture_coordinate_indices.cpu().numpy().flatten()]\n",
    "\n",
    "mesh = trimesh.Trimesh(\n",
    "    vertices=duplicated_vertices,\n",
    "    faces=duplicated_faces,\n",
    "    process=False,\n",
    "    maintain_order=True\n",
    ")\n",
    "\n",
    "material = trimesh.visual.material.PBRMaterial(\n",
    "    baseColorFactor=np.ones(4),\n",
    "    baseColorTexture=body_parts_segmentation_image,\n",
    "    metallicFactor=0.5,\n",
    "    doubleSided=True,\n",
    "    )\n",
    "import trimesh.visual\n",
    "mesh.visual = trimesh.visual.texture.TextureVisuals(\n",
    "        uv=duplicated_uvs,\n",
    "        material=material\n",
    "    )\n",
    "\n",
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the central color of each face\n",
    "body_parts_segmentation_array = np.asarray(body_parts_segmentation_image)\n",
    "face_center_texture_coordinates = anny_model.texture_coordinates[anny_model.face_texture_coordinate_indices].mean(dim=1)\n",
    "\n",
    "u = torch.round(face_center_texture_coordinates[:, 0] * body_parts_segmentation_array.shape[1]).to(dtype=torch.int64).clamp_max(body_parts_segmentation_array.shape[0] - 1).detach().cpu().numpy()\n",
    "v = torch.round((1-face_center_texture_coordinates[:, 1]) * body_parts_segmentation_array.shape[0]).to(dtype=torch.int64).clamp_max(body_parts_segmentation_array.shape[1] - 1).detach().cpu().numpy()\n",
    "\n",
    "face_colors = body_parts_segmentation_array[v,u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the head based on face colors\n",
    "face_mask = np.zeros(len(faces), dtype=bool)\n",
    "\n",
    "labels = [\"head\", \"eye_cavity.R\", \"eye_cavity.L\", \"mouth_cavity\", \"eye_front.L\", \"eye_back.L\", \"eye_front.R\", \"eye_back.L\", \"tongue\"]\n",
    "for label in labels:\n",
    "    face_mask |= np.all(face_colors == np.asarray(body_parts_segmentation['colors'][label]), axis=-1)\n",
    "\n",
    "trimesh.Trimesh(vertices=vertices,\n",
    "                faces=faces[face_mask],).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
