{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Parameterizing shapes with Anny\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Instantiate the model\n",
    "Anny is shipped as a Python package that can be easily installed (see the README for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Markdown, display\n",
    "import torch\n",
    "import roma # A PyTorch library useful to deal with space transformations.\n",
    "import anny # The main library for the Anny model.\n",
    "import trimesh # For 3D mesh visualization.\n",
    "\n",
    "# Instantiate the model, with all shape parameters available.\n",
    "# Remark: the first instantiation may take a while. Latter calls will be faster thanks to caching.\n",
    "anny_model = anny.create_fullbody_model(eyes=True, tongue=False, all_phenotypes=True, local_changes=True, remove_unattached_vertices=True)\n",
    "# Use 32bit floating point precision on the CPU for this demo.\n",
    "dtype = torch.float32\n",
    "device = torch.device('cpu')\n",
    "anny_model = anny_model.to(device=device, dtype=dtype)\n",
    "\n",
    "# A simple transform to get a better view angle in 3D mesh visualizations.\n",
    "trimesh_scene_transform = roma.Rigid(linear=roma.euler_to_rotmat('x', [-90.], degrees=True), translation=None).to_homogeneous().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Template mesh\n",
    "This is the template mesh of Anny:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"{anny_model.template_vertices.shape[0]} vertices -- {anny_model.faces.shape[0]} faces composed of {anny_model.faces.shape[1]} vertices each.\"))\n",
    "trimesh.Trimesh(vertices=anny_model.template_vertices.cpu().numpy(), faces=anny_model.faces.cpu().numpy()).apply_transform(trimesh_scene_transform).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Shape parameterization\n",
    "\n",
    "Anny can model a diversity of morphologies.\n",
    "We follow MakeHuman terminology, and parameterize diversity of body shapes using a set of *phenotype* parameters, typically between 0 and 1.\n",
    "\n",
    "*Note:* the values *african*, *caucasian* and *asian* parameters are normalized so that they sum to 1.\n",
    "\n",
    "**Word of caution regarding phenotypes:**\n",
    "*Phenotypes are based on preconceptions of artists regarding particular human traits. As a result, they encode by design stereotypes of MakeHuman artists, and one should not expect phenotype parameters to faithfully encode identity-related characteristics, such as gender, age or ethnicity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List phenotype parameters\n",
    "Markdown(\"**List of phenotype parameters**: \" + \", \".join([f\"{label}\" for label in anny_model.phenotype_labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Here we show an example of how the **age** parameter influences the resulting mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5  # We can process multiple bodies at once in a batch. \n",
    "\n",
    "phenotype_kwargs = {key : torch.full((batch_size,), fill_value=0.5, dtype=dtype, device=device) for key in anny_model.phenotype_labels}\n",
    "phenotype_kwargs['age'] = torch.linspace(0., 1., batch_size, dtype=dtype, device=device) # Example: vary the age parameter across the batch.\n",
    "output = anny_model(phenotype_kwargs=phenotype_kwargs)\n",
    "\n",
    "scene = trimesh.Scene()\n",
    "for i in range(batch_size):\n",
    "    # Create a mesh for each body in the batch.\n",
    "    mesh = trimesh.Trimesh(vertices=output['vertices'][i].squeeze().cpu().numpy(), faces=anny_model.faces.cpu().numpy())\n",
    "    transform = roma.Rigid(linear=None, translation=torch.tensor([i * 1., 0., 0.], dtype=dtype, device=device)).to_homogeneous().cpu().numpy()\n",
    "    scene.add_geometry(mesh, transform=transform)\n",
    "\n",
    "scene.apply_transform(trimesh_scene_transform)  # Rotate the scene to have a better view.\n",
    "scene.show()  # This will open a window to visualize the scene with all the bodies in it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Local changes\n",
    "Additionnally one specify some more local morphological changes.\n",
    "Local change parameters values are typically expected to be chosen between -1 and 1, but one can use values outside this range to extrapolate changes even further.\n",
    "\n",
    "*Note: it is easy to produce unrealistic meshes when using significant local changes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"**List of local changes parameters:** \" + \", \".join(anny_model.local_change_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Local change example\n",
    "\n",
    "We show here the effect of the *stomach-pregnant-incr* local change parameter, as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3  # We can process multiple faces at once in a batch.\n",
    "pose_parameters = roma.Rigid.identity(dim=3, batch_shape=(batch_size, anny_model.bone_count)).to_homogeneous()\n",
    "phenotype_kwargs = {key : torch.full((batch_size,), fill_value=0.5) for key in anny_model.phenotype_labels}\n",
    "# In this example, we start from a stereotypical young adult woman mesh\n",
    "phenotype_kwargs['age'].fill_(0.67) \n",
    "phenotype_kwargs['gender'].fill_(1.)\n",
    "\n",
    "local_changes = {'stomach-pregnant-incr': torch.linspace(0, 1., batch_size)}  # Example: vary the upperarm fat increment across the batch.\n",
    "output = anny_model(phenotype_kwargs=phenotype_kwargs, local_changes_kwargs=local_changes)\n",
    "\n",
    "scene = trimesh.Scene()\n",
    "for i in range(batch_size):\n",
    "    # Create a mesh for each face in the batch.\n",
    "    mesh = trimesh.Trimesh(vertices=output['vertices'][i].squeeze().cpu().numpy(), faces=anny_model.faces.cpu().numpy())\n",
    "    transform = roma.Rigid(linear=None, translation=torch.tensor([i * 1., 0., 0.])).to_homogeneous().cpu().numpy()\n",
    "    scene.add_geometry(mesh, transform=transform)\n",
    "scene.apply_transform(trimesh_scene_transform)  # Rotate the scene to have a better view.\n",
    "scene.show()  # This will open a window to visualize the scene with all the faces in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Phenotype distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anny.shape_distribution\n",
    "import anny.anthropometry\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "phenotype_distribution = anny.shape_distribution.SimpleShapeDistribution(anny_model,\n",
    "            morphological_age_distribution=torch.distributions.Uniform(low=0.0, high=60.0))\n",
    "\n",
    "real_age, phenotype_kwargs = phenotype_distribution.sample(batch_size=200)\n",
    "output = anny_model(phenotype_kwargs=phenotype_kwargs)\n",
    "\n",
    "scene = trimesh.Scene()\n",
    "i = -1\n",
    "for u in range(4):\n",
    "    for v in range(5):\n",
    "        i += 1\n",
    "        assert i < output['vertices'].shape[0], \"Batch size is too small for the grid.\"\n",
    "        # Create a mesh for each face in the batch.\n",
    "        mesh = trimesh.Trimesh(vertices=output['vertices'][i].squeeze().cpu().numpy(), faces=anny_model.faces.cpu().numpy())\n",
    "        transform = roma.Rigid(linear=None, translation=torch.tensor([v * 1., u * 1., 0.], dtype=dtype, device=device)).to_homogeneous().cpu().numpy()\n",
    "        scene.add_geometry(mesh, transform=transform)\n",
    "scene.apply_transform(trimesh_scene_transform)  # Rotate the scene to have a better view.\n",
    "scene.show()  # This will open a window to visualize the scene with all the faces in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Body measures\n",
    "\n",
    "We additionnally provide a class to estimate some anthropometric measurements, assuming a body buoyancy of .98 in water. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_age, phenotype_kwargs = phenotype_distribution.sample(batch_size=1000)\n",
    "output = anny_model(phenotype_kwargs=phenotype_kwargs)\n",
    "\n",
    "measurements = anny.anthropometry.Anthropometry(anny_model)\n",
    "measures = measurements(output['rest_vertices'])\n",
    "\n",
    "fig, axes = plt.subplots(1,3, squeeze=True, figsize=(10, 5))\n",
    "axes[0].scatter(real_age.cpu().numpy(), measures['height'].cpu().numpy())\n",
    "axes[0].set_xlabel('Morphological age (year)')\n",
    "axes[0].set_ylabel('Height (m)')\n",
    "axes[1].scatter(real_age.cpu().numpy(), measures['waist_circumference'].cpu().numpy())\n",
    "axes[1].set_xlabel('Morphological age (year)')\n",
    "axes[1].set_ylabel('Waist circumference (m)')\n",
    "axes[2].scatter(real_age.cpu().numpy(), measures['bmi'].cpu().numpy())\n",
    "axes[2].set_xlabel('Morphological age (year)')\n",
    "axes[2].set_ylabel('Body Mass Index estimate')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
